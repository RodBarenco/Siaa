# ğŸ¤– Siaa â€” Scaffoldable IA Assistant

Assistente de IA pessoal, modular e escalÃ¡vel. Combina **SVM** para classificaÃ§Ã£o de intenÃ§Ãµes com **Granite LLM** (via Ollama local) e integraÃ§Ã£o com **Telegram**.

Projetado para rodar em VPS Oracle Free Tier (ARM) com Docker.

---

## ğŸ“¦ MÃ³dulos

| MÃ³dulo | DescriÃ§Ã£o | Porta interna |
|--------|-----------|---------------|
| [ğŸ¤– Siaa](./src/siaa/readme.md) | Core do assistente â€” SVM, LLM, memÃ³ria, entidades | 8000 |
| [ğŸŒ Siaa-Proxy](./src/siaa-proxy/README.md) | Gerenciador de proxies com cron jobs e navegador serverless | 8001 |
| [ğŸ” Siaa-Vault](./src/siaa-vault/README.md) | Cofre de credenciais com criptografia Fernet e JWT | 8002 |

---

## ğŸ—ï¸ Estrutura do Projeto

```
/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env                    â† variÃ¡veis globais (nÃ£o commitar)
â”œâ”€â”€ .env.example
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ siaa/               â† core do assistente
â”‚   â”œâ”€â”€ siaa-proxy/         â† gerenciador de proxies
â”‚   â””â”€â”€ siaa-vault/         â† cofre de credenciais
â”‚
â”œâ”€â”€ nginx/
â”‚   â””â”€â”€ nginx.conf
â”‚
â””â”€â”€ volumes/
    â”œâ”€â”€ siaa-data/          â† contextos, banco e datasets do Siaa
    â”œâ”€â”€ proxy-data/         â† banco do siaa-proxy
    â”œâ”€â”€ vault-data/         â† banco do siaa-vault (sensÃ­vel)
    â””â”€â”€ config/             â† config.json compartilhado
```

---

## ğŸ§  Como funciona

```
Telegram
   â”‚
   â–¼
Siaa (app.py)
   â”œâ”€â”€ SVM classifica a intenÃ§Ã£o (rÃ¡pido, local)
   â”œâ”€â”€ Granite LLM processa linguagem (Ollama)
   â”œâ”€â”€ Entity executa a aÃ§Ã£o
   â”‚     â”œâ”€â”€ web_actions/ â†’ chama Siaa-Proxy para navegar
   â”‚     â””â”€â”€ web_actions/ â†’ chama Siaa-Vault para credenciais
   â””â”€â”€ MemÃ³ria em 4 camadas atualiza contexto
```

---

## ğŸš€ Quick Start

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/RodBarenco/Siaa.git
cd Siaa

# 2. Configure as variÃ¡veis de ambiente
cp .env.example .env
# edite o .env com suas chaves

# 3. Suba os containers
docker compose up -d

# 4. Instale o modelo Granite no Ollama
docker exec -it ollama ollama pull granite3.1-dense:2b
```

---

## ğŸ“‹ PrÃ©-requisitos

- Docker + Docker Compose
- Conta Oracle Cloud (Free Tier ARM â€” 4 OCPU / 24GB RAM)
- Bot do Telegram ([@BotFather](https://t.me/botfather))

---

ğŸ—ºï¸ Roadmap de Desenvolvimento

    [x] Core SVM + Granite LLM

    [x] IntegraÃ§Ã£o Telegram (Texto/Ãudio)

    [x] MemÃ³ria em 4 camadas (Flash, Short, Medium, Long term)

    [x] Scaffolding de mÃ³dulos (add_module.py)

    [x] Siaa-Proxy (Gerenciador de proxies)

    [x] Siaa-Vault (Cofre de credenciais)

    [ ] ReconfiguraÃ§Ã£o da ordenaÃ§Ã£o MVC para Arquitetura Modular

    [ ] CriaÃ§Ã£o de novos mÃ³dulos bÃ¡sicos (FinanÃ§as, SaÃºde, Clima)

    [ ] Docker Compose completo com Nginx Router

    [ ] Melhoria na usabilidade: Evitar chamadas desnecessÃ¡rias Ã  LLM

    [ ] ServiÃ§o de lembretes e tarefas agendadas (Cron Jobs)

    [ ] Suite de testes automatizados

    [ ] Extensibilidade externa via interface de integraÃ§Ã£o

    [ ] Nginx como Gateway para evitar exposiÃ§Ã£o de portas

    [ ] Redis para cache rÃ¡pido de contexto

    [ ] Procura vetorial com Embeddings (RAG de longo prazo)
